{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords e simbolos a retirar\n",
    "stop_words = set(['de','a','o','que','e','é','do','da','em','um','para','com','não','uma','os','no','se','na','por','mais','as','dos','como','mas','ao','ele','das','à','seu','sua','ou','quando','muito','nos','já','eu','também','só','pelo','pela','até','isso','ela','entre','depois','sem','mesmo','aos','seus','quem','nas','me','esse','eles','você','essa','num','nem','suas','meu','às','minha','numa','pelos','elas','qual','nós','lhe','deles','essas','esses','pelas','este','dele','tu','te','vocês','vos','lhes','meus','minhas','teu','tua','teus','tuas','nosso','nossa','nossos','nossas','dela','delas','esta','estes','estas','aquele','aquela','aqueles','aquelas','isto','aquilo','estou','está','estamos','estão','estive','esteve','estivemos','estiveram','estava','estávamos','estavam','estivera','estivéramos','esteja','estejamos','estejam','estivesse','estivéssemos','estivessem','estiver','estivermos','estiverem','hei','há','havemos','hão','houve','houvemos','houveram','houvera','houvéramos','haja','hajamos','hajam','houvesse','houvéssemos','houvessem','houver','houvermos','houverem','houverei','houverá','houveremos','houverão','houveria','houveríamos','houveriam','sou','somos','são','era','éramos','eram','fui','foi','fomos','foram','fora','fôramos','seja','sejamos','sejam','fosse','fôssemos','fossem','for','formos','forem','serei','será','seremos','serão','seria','seríamos','seriam','tenho','tem','temos','tém','tinha','tínhamos','tinham','tive','teve','tivemos','tiveram','tivera','tivéramos','tenha','tenhamos','tenham','tivesse','tivéssemos','tivessem','tiver','tivermos','tiverem','terei','terá','teremos','terão','teria','teríamos','teriam'])\n",
    "\n",
    "symbols = set(['-', 'r$', 'R$', '.'])\n",
    "\n",
    "# Doria\n",
    "# separando as palavras\n",
    "palavras = \"\".join(politicos['Doria']['text']).lower().split()\n",
    "# returando stopwords e depois os web links\n",
    "palavras = [w for w in palavras if not w in (stop_words | symbols)]\n",
    "palavras = [w for w in palavras if re.match(r'https://*', w) == None]\n",
    "\n",
    "c = Counter(palavras)\n",
    "# retirando palavras com frequencia menor do que 5 e adicionando número ao candidato\n",
    "dados = {(1,x,y) for x,y in zip(c,c.values()) if y > 5}\n",
    "print(\"Doria\", len(dados))\n",
    "\n",
    "# Bolsonaro\n",
    "palavras = \"\".join(politicos['Bolsonaro']['text']).lower().split()\n",
    "palavras = [w for w in palavras if not w in (stop_words | symbols)]\n",
    "palavras = [w for w in palavras if re.match(r'https://*', w) == None]\n",
    "\n",
    "c = Counter(palavras)\n",
    "d = {(2,x,y) for x,y in zip(c,c.values()) if y > 5}\n",
    "print(\"Bolsonaro\", len(d))\n",
    "# adicionando aos dados\n",
    "for x in d:\n",
    "    dados.add(x)\n",
    "\n",
    "# Lula\n",
    "palavras = \"\".join(politicos['Lula']['text']).lower().split()\n",
    "palavras = [w for w in palavras if not w in (stop_words | symbols)]\n",
    "palavras = [w for w in palavras if re.match(r'https://*', w) == None]\n",
    "\n",
    "c = Counter(palavras)\n",
    "d = {(3,x,y) for x,y in zip(c,c.values()) if y > 5}\n",
    "print(\"Lula\", len(d))\n",
    "for x in d:\n",
    "    dados.add(x)\n",
    "\n",
    "print(\"Total\", len(dados))\n",
    "\n",
    "# montando o dataframe\n",
    "df = pd.DataFrame(dados, columns=['candidato', 'texto', 'frequencia'])\n",
    "df.sort_values('frequencia', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'palavras' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8426a233c749>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpalavras_unicas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnumero_total_palavras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpalavras\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mpalavras_unicas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'palavras' is not defined"
     ]
    }
   ],
   "source": [
    "palavras_unicas = set()\n",
    "numero_total_palavras = 0\n",
    "for c in palavras:\n",
    "    for p in c:\n",
    "        palavras_unicas.add(p)\n",
    "        numero_total_palavras += 1\n",
    "print(numero_total_palavras, len(palavras_unicas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Bag of word sentence 1:\n",
      "{'likes': 2, 'movies': 2, 'john': 1, 'to': 1, 'watch': 1, 'mary': 1, 'too': 1}\n",
      "We found 7 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sentence = [\"John likes to watch movies. Mary likes movies too.\"]\n",
    "\n",
    "def print_bow(sentence: str) -> None:\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(sentence)\n",
    "    sequences = tokenizer.texts_to_sequences(sentence)\n",
    "    word_index = tokenizer.word_index \n",
    "    bow = {}\n",
    "    for key in word_index:\n",
    "        bow[key] = sequences[0].count(word_index[key])\n",
    "\n",
    "    print(f\"Bag of word sentence 1:\\n{bow}\")\n",
    "    print(f'We found {len(word_index)} unique tokens.')\n",
    "\n",
    "print_bow(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe com todos os politicos e seus tweets\n",
    "lista_dir = os.listdir(\"./politicos/\")\n",
    "nome_politicos = []\n",
    "df_politicos = pd.DataFrame()\n",
    "for nome in lista_dir:\n",
    "    df_politico = pd.read_csv(\n",
    "        f\"./politicos/{nome}\",\n",
    "        delimiter=\",\",\n",
    "        encoding='utf-8',\n",
    "        usecols=[1,2,8]\n",
    "    )\n",
    "    df_politico['nome'] = nome[:-4]\n",
    "    nome_politicos.append(nome[:-4])\n",
    "    df_politicos = df_politicos.append(df_politico)\n",
    "cols = ['nome'] + [col for col in df_politicos if col != 'nome']\n",
    "df_politicos = df_politicos[cols]\n",
    "df_politicos.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       index    nome            created_at  \\\n",
       "0          0  Amoedo  2021-04-19T16:18:20Z   \n",
       "1          1  Amoedo  2021-04-19T16:05:53Z   \n",
       "2          2  Amoedo  2021-04-19T15:32:40Z   \n",
       "3          3  Amoedo  2021-04-19T12:53:14Z   \n",
       "4          4  Amoedo  2021-04-19T12:25:58Z   \n",
       "...      ...     ...                   ...   \n",
       "31628   1290    Moro  2019-04-04T16:21:34Z   \n",
       "31629   1291    Moro  2019-04-04T13:39:55Z   \n",
       "31630   1292    Moro  2019-04-04T13:39:13Z   \n",
       "31631   1293    Moro  2019-04-04T13:37:30Z   \n",
       "31632   1294    Moro  2019-04-04T13:36:29Z   \n",
       "\n",
       "                                                    text                   id  \n",
       "0      RT @MBLivre: Presidente americano Joe Biden an...  1384179569712713735  \n",
       "1      Temos que fazer a nossa parte. Não podemos dei...  1384176435552608259  \n",
       "2      O governo federal e o Congresso ignoraram no O...  1384168077697314825  \n",
       "3      RT @o_antagonista: .@joaoamoedonovo sugeriu no...  1384127951311040517  \n",
       "4                         Informações de @OGloboPolitica  1384121090243383296  \n",
       "...                                                  ...                  ...  \n",
       "31628  Uma foto que diz muito. Orgulho da Força Nacio...  1113839032813879301  \n",
       "31629  Quero explicar aqui o projeto de lei anticrime...  1113798354134347777  \n",
       "31630  Nem sempre poderei estar por aqui, pois o trab...  1113798178581696513  \n",
       "31631  Resolvi aderir ao twitter pois é um instrument...  1113797744861360128  \n",
       "31632  Ola, bom dia, há muitas páginas de apoio e até...  1113797489562460160  \n",
       "\n",
       "[31633 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>nome</th>\n      <th>created_at</th>\n      <th>text</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Amoedo</td>\n      <td>2021-04-19T16:18:20Z</td>\n      <td>RT @MBLivre: Presidente americano Joe Biden an...</td>\n      <td>1384179569712713735</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Amoedo</td>\n      <td>2021-04-19T16:05:53Z</td>\n      <td>Temos que fazer a nossa parte. Não podemos dei...</td>\n      <td>1384176435552608259</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Amoedo</td>\n      <td>2021-04-19T15:32:40Z</td>\n      <td>O governo federal e o Congresso ignoraram no O...</td>\n      <td>1384168077697314825</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Amoedo</td>\n      <td>2021-04-19T12:53:14Z</td>\n      <td>RT @o_antagonista: .@joaoamoedonovo sugeriu no...</td>\n      <td>1384127951311040517</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Amoedo</td>\n      <td>2021-04-19T12:25:58Z</td>\n      <td>Informações de @OGloboPolitica</td>\n      <td>1384121090243383296</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31628</th>\n      <td>1290</td>\n      <td>Moro</td>\n      <td>2019-04-04T16:21:34Z</td>\n      <td>Uma foto que diz muito. Orgulho da Força Nacio...</td>\n      <td>1113839032813879301</td>\n    </tr>\n    <tr>\n      <th>31629</th>\n      <td>1291</td>\n      <td>Moro</td>\n      <td>2019-04-04T13:39:55Z</td>\n      <td>Quero explicar aqui o projeto de lei anticrime...</td>\n      <td>1113798354134347777</td>\n    </tr>\n    <tr>\n      <th>31630</th>\n      <td>1292</td>\n      <td>Moro</td>\n      <td>2019-04-04T13:39:13Z</td>\n      <td>Nem sempre poderei estar por aqui, pois o trab...</td>\n      <td>1113798178581696513</td>\n    </tr>\n    <tr>\n      <th>31631</th>\n      <td>1293</td>\n      <td>Moro</td>\n      <td>2019-04-04T13:37:30Z</td>\n      <td>Resolvi aderir ao twitter pois é um instrument...</td>\n      <td>1113797744861360128</td>\n    </tr>\n    <tr>\n      <th>31632</th>\n      <td>1294</td>\n      <td>Moro</td>\n      <td>2019-04-04T13:36:29Z</td>\n      <td>Ola, bom dia, há muitas páginas de apoio e até...</td>\n      <td>1113797489562460160</td>\n    </tr>\n  </tbody>\n</table>\n<p>31633 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df_politicos"
   ]
  },
  {
   "source": [
    "# TOKENIZER TIPO TYNITTEXT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    doc = nlp.tokenizer(sent)\n",
    "    return [token.lower_ for token in doc if not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnest_tokens(df, # line-based dataframe\n",
    "                  column_to_tokenize, # name of the column with the text\n",
    "                  new_token_column_name='word', # what you want the column of words to be called\n",
    "                  tokenizer_function=tokenize): # what tokenizer to use\n",
    "    \n",
    "    return (df[column_to_tokenize]\n",
    "              .apply(tokenizer_function)\n",
    "              .apply(pd.Series)\n",
    "              .stack()\n",
    "              .reset_index(level=0)\n",
    "              .set_index('level_0')\n",
    "              .rename(columns={0: new_token_column_name})\n",
    "              .join(df.drop(column_to_tokenize, 1), how='left')\n",
    "              .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              word  index    nome            created_at                   id\n",
       "0               rt      0  Amoedo  2021-04-19T16:18:20Z  1384179569712713735\n",
       "1         @mblivre      0  Amoedo  2021-04-19T16:18:20Z  1384179569712713735\n",
       "2       presidente      0  Amoedo  2021-04-19T16:18:20Z  1384179569712713735\n",
       "3        americano      0  Amoedo  2021-04-19T16:18:20Z  1384179569712713735\n",
       "4              joe      0  Amoedo  2021-04-19T16:18:20Z  1384179569712713735\n",
       "...            ...    ...     ...                   ...                  ...\n",
       "905716           é   1294    Moro  2019-04-04T13:36:29Z  1113797489562460160\n",
       "905717         meu   1294    Moro  2019-04-04T13:36:29Z  1113797489562460160\n",
       "905718       mesmo   1294    Moro  2019-04-04T13:36:29Z  1113797489562460160\n",
       "905719      sergio   1294    Moro  2019-04-04T13:36:29Z  1113797489562460160\n",
       "905720        moro   1294    Moro  2019-04-04T13:36:29Z  1113797489562460160\n",
       "\n",
       "[905721 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>index</th>\n      <th>nome</th>\n      <th>created_at</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rt</td>\n      <td>0</td>\n      <td>Amoedo</td>\n      <td>2021-04-19T16:18:20Z</td>\n      <td>1384179569712713735</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@mblivre</td>\n      <td>0</td>\n      <td>Amoedo</td>\n      <td>2021-04-19T16:18:20Z</td>\n      <td>1384179569712713735</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>presidente</td>\n      <td>0</td>\n      <td>Amoedo</td>\n      <td>2021-04-19T16:18:20Z</td>\n      <td>1384179569712713735</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>americano</td>\n      <td>0</td>\n      <td>Amoedo</td>\n      <td>2021-04-19T16:18:20Z</td>\n      <td>1384179569712713735</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>joe</td>\n      <td>0</td>\n      <td>Amoedo</td>\n      <td>2021-04-19T16:18:20Z</td>\n      <td>1384179569712713735</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>905716</th>\n      <td>é</td>\n      <td>1294</td>\n      <td>Moro</td>\n      <td>2019-04-04T13:36:29Z</td>\n      <td>1113797489562460160</td>\n    </tr>\n    <tr>\n      <th>905717</th>\n      <td>meu</td>\n      <td>1294</td>\n      <td>Moro</td>\n      <td>2019-04-04T13:36:29Z</td>\n      <td>1113797489562460160</td>\n    </tr>\n    <tr>\n      <th>905718</th>\n      <td>mesmo</td>\n      <td>1294</td>\n      <td>Moro</td>\n      <td>2019-04-04T13:36:29Z</td>\n      <td>1113797489562460160</td>\n    </tr>\n    <tr>\n      <th>905719</th>\n      <td>sergio</td>\n      <td>1294</td>\n      <td>Moro</td>\n      <td>2019-04-04T13:36:29Z</td>\n      <td>1113797489562460160</td>\n    </tr>\n    <tr>\n      <th>905720</th>\n      <td>moro</td>\n      <td>1294</td>\n      <td>Moro</td>\n      <td>2019-04-04T13:36:29Z</td>\n      <td>1113797489562460160</td>\n    </tr>\n  </tbody>\n</table>\n<p>905721 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "unnest_tokens(df_politicos, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}